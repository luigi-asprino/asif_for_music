{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import faiss \n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from asif import extract_candidate_sets_from_clusters\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loading precomputed embeddings...\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"data\"\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "lyrics = pickle.load(open(f\"{data_folder}/lyrics.pkl\", \"rb\"))\n",
    "chords = pickle.load(open(f\"{data_folder}/chords.pkl\", \"rb\"))\n",
    "artist_song = pickle.load(open(f\"{data_folder}/artist_song.pkl\", \"rb\"))\n",
    "\n",
    "print(\"Loading precomputed embeddings...\")\n",
    "chords_embeddings = pickle.load(open(f\"{data_folder}/chords_embeddings_sbert_chocolm.pkl\", \"rb\"))\n",
    "lyrics_embeddings = pickle.load(open(f\"{data_folder}/lyrics_embeddings_sbert_roberta.pkl\", \"rb\"))\n",
    "\n",
    "kmeans_lyrics = pickle.load(open(f\"{data_folder}/lyrics_kmeans.pkl\", \"rb\"))\n",
    "kmeans_chords = pickle.load(open(f\"{data_folder}/chords_kmeans.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "# find candidates by sampling each cluster\n",
    "# proceeds with asif\n",
    "\n",
    "def compute_relative_coordinates(candidate_embeddings, embeddings, denoise_and_normalize=True, k=800, p=8):\n",
    "        \n",
    "        sim = (1 / (1 + torch.cdist(candidate_embeddings, embeddings)))\n",
    "\n",
    "        if not denoise_and_normalize:\n",
    "              return sim\n",
    "        \n",
    "        result = torch.zeros(sim.size())\n",
    "        \n",
    "        for i, j in enumerate(torch.argsort(sim, descending=True)[:,:k]):\n",
    "            result[i][j] = p\n",
    "\n",
    "        return torch.nn.functional.normalize(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_coordinates_chord_clusters = compute_relative_coordinates(torch.from_numpy(kmeans_chords.cluster_centers_), chords_embeddings)\n",
    "relative_coordinates_lyrics_clusters = compute_relative_coordinates(torch.from_numpy(kmeans_lyrics.cluster_centers_), lyrics_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_self_relative_coordinates(embeddings, anchors, batch_size=1_000, device=\"cpu\"):\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    for i in tqdm(range(0, embeddings.size()[0], batch_size)):\n",
    "        self_relative_coordinates_batch = compute_relative_coordinates(embeddings[i:min(i+batch_size, embeddings.size()[0])], embeddings)\n",
    "        self_relative_coordinates_batch = self_relative_coordinates_batch.to(device)\n",
    "        relative_coordinates_vs_anchors = compute_relative_coordinates(self_relative_coordinates_batch, anchors, denoise_and_normalize=False)\n",
    "        relative_coordinates_vs_anchors = relative_coordinates_vs_anchors.to(\"cpu\")\n",
    "        result.append(relative_coordinates_vs_anchors)\n",
    "    \n",
    "    return torch.vstack(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 2206/35173 [18:45<4:40:21,  1.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m anchors \u001b[38;5;241m=\u001b[39m anchors\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m chords_embeddings \u001b[38;5;241m=\u001b[39m chords_embeddings\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m relative_coordinates \u001b[38;5;241m=\u001b[39m compute_self_relative_coordinates(chords_embeddings, anchors, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mcompute_self_relative_coordinates\u001b[0;34m(embeddings, anchors, batch_size, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, embeddings\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m], batch_size)):\n\u001b[0;32m----> 6\u001b[0m     self_relative_coordinates_batch \u001b[38;5;241m=\u001b[39m compute_relative_coordinates(embeddings[i:\u001b[38;5;28mmin\u001b[39m(i\u001b[38;5;241m+\u001b[39mbatch_size, embeddings\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m])], embeddings)\n\u001b[1;32m      7\u001b[0m     self_relative_coordinates_batch \u001b[38;5;241m=\u001b[39m self_relative_coordinates_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     relative_coordinates_vs_anchors \u001b[38;5;241m=\u001b[39m compute_relative_coordinates(self_relative_coordinates_batch, anchors, denoise_and_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mcompute_relative_coordinates\u001b[0;34m(candidate_embeddings, embeddings, denoise_and_normalize, k, p)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m denoise_and_normalize:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sim\n\u001b[0;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(sim\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(torch\u001b[38;5;241m.\u001b[39margsort(sim, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:,:k]):\n\u001b[1;32m     15\u001b[0m     result[i][j] \u001b[38;5;241m=\u001b[39m p\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "anchors = torch.vstack([relative_coordinates_chord_clusters, relative_coordinates_lyrics_clusters])\n",
    "anchors = anchors.to(\"cuda:0\")\n",
    "chords_embeddings = chords_embeddings.to(\"cuda:0\")\n",
    "relative_coordinates = compute_self_relative_coordinates(chords_embeddings, anchors, batch_size=100, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_candidates_ids = extract_candidate_sets_from_clusters(kmeans_lyrics.n_clusters, kmeans_lyrics.labels_, lyrics, retrieve_ids=True)\n",
    "chords_candidates_ids = extract_candidate_sets_from_clusters(kmeans_chords.n_clusters, kmeans_chords.labels_, lyrics, retrieve_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500032 486031\n",
      "103253\n"
     ]
    }
   ],
   "source": [
    "n_of_candidates = 500_000\n",
    "n_of_lyrics_per_cluster = math.ceil(n_of_candidates / kmeans_lyrics.n_clusters)\n",
    "n_of_chords_per_cluster = math.ceil(n_of_candidates / kmeans_chords.n_clusters)\n",
    "\n",
    "lyrics_candidates_ids_sampled = {cluster_id: random.sample(cluster, min(n_of_lyrics_per_cluster, len(cluster))) for cluster_id, cluster in lyrics_candidates_ids.items()}\n",
    "chords_candidates_ids_sampled = {cluster_id: random.sample(cluster, min(n_of_chords_per_cluster, len(cluster))) for cluster_id, cluster in chords_candidates_ids.items()}\n",
    "\n",
    "sampled_chords = [chords for cluster in chords_candidates_ids_sampled.values() for chords in cluster]\n",
    "sampled_lyrics = [lyrics for cluster in lyrics_candidates_ids_sampled.values() for lyrics in cluster]\n",
    "\n",
    "print(len(sampled_chords), len(sampled_lyrics))\n",
    "\n",
    "print(len(set(sampled_chords) & set(sampled_lyrics)))\n",
    "\n",
    "anchors_ids = sorted(list(set(sampled_chords) & set(sampled_lyrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_chord_embeddings = chords_embeddings[anchors_ids]\n",
    "anchors_lyrics_embeddings = lyrics_embeddings[anchors_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = faiss.StandardGpuResources() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "lyrics_index = faiss.IndexFlatL2(kmeans_lyrics.cluster_centers_.shape[1])   # build the index\n",
    "gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, lyrics_index)\n",
    "\n",
    "print(gpu_index_flat.is_trained)\n",
    "gpu_index_flat.add(kmeans_lyrics.cluster_centers_)                  # add vectors to the index\n",
    "print(gpu_index_flat.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000000\n",
      "1000000 2000000\n",
      "2000000 3000000\n",
      "3000000 3517221\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 1_000_000\n",
    "for i in range(0, len(lyrics_embeddings), chunk_size):\n",
    "    print(i, min(i+chunk_size, len(lyrics_embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initialising asif...\")\n",
    "asif = ASIF(\n",
    "    lyrics_candidates,\n",
    "    chords_candidates,\n",
    "    torch.from_numpy(kmeans_lyrics.cluster_centers_),\n",
    "    torch.from_numpy(kmeans_chords.cluster_centers_),\n",
    "    lyrics_embeddings,\n",
    "    chords_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3517221, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1 / (1 + torch.cdist(candidate_embeddings, embeddings)))\n",
    "D = 1 / (1 + torch.cdist(lyrics_embeddings, torch.from_numpy(kmeans_lyrics.cluster_centers_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4046, 0.4699, 0.3783, 0.4046, 0.4915, 0.3568, 0.3041, 0.4217, 0.4260,\n",
       "        0.2637, 0.4239, 0.4301, 0.4801, 0.3477, 0.4009, 0.4156, 0.3465, 0.5012,\n",
       "        0.5070, 0.4362, 0.4472, 0.4021, 0.3839, 0.4087, 0.3904, 0.3391, 0.3890,\n",
       "        0.2890, 0.4971, 0.4680, 0.4450, 0.3502, 0.4416, 0.2477, 0.3754, 0.4043,\n",
       "        0.3593, 0.3681, 0.3934, 0.3286, 0.4110, 0.4669, 0.3430, 0.3555, 0.4246,\n",
       "        0.4473, 0.4002, 0.5011, 0.4886, 0.3456, 0.3676, 0.3959, 0.1414, 0.3203,\n",
       "        0.3993, 0.3474, 0.3074, 0.4624, 0.4558, 0.3747, 0.4049, 0.4857, 0.4738,\n",
       "        0.2195])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.size()\n",
    "D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 17 47 ... 33 63 52]\n",
      " [ 4 18 28 ... 33 63 52]\n",
      " [ 4 18 61 ... 33 63 52]\n",
      " ...\n",
      " [58 48 12 ... 33 63 52]\n",
      " [58 44 19 ... 33 63 52]\n",
      " [58 48 12 ... 33 63 52]]\n"
     ]
    }
   ],
   "source": [
    "k = 800                          # we want to see 4 nearest neighbors\n",
    "D, I = gpu_index_flat.search(lyrics_embeddings.numpy()[:1000], gpu_index_flat.ntotal) # sanity check\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2376192"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:118] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 22585153683456 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2376192\u001b[39m, \u001b[38;5;241m2376192\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:118] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 22585153683456 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "torch.zeros((2376192, 2376192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:118] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 49483374251364 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((lyrics_embeddings\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m], lyrics_embeddings\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(I):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m row:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:118] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 49483374251364 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "p = 8\n",
    "result = torch.zeros((lyrics_embeddings.size()[0], lyrics_embeddings.size()[0]))\n",
    "for i, row in enumerate(I):\n",
    "    for j in row:\n",
    "        result[i][j] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_coordinates(vectors, db, k):\n",
    "    D, I = db.search(vectors, k) # sanity check\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      0, 2766256,  244114, 3333898, 1985832, 1090844, 3020608,\n",
       "       2906870,  212403, 2111220, 1755655, 1755687, 2647155, 1856240,\n",
       "       2556382, 2556394, 1856225, 1856237, 2668070, 1578963, 2668058,\n",
       "       1856252, 1578974, 2001890, 1626605, 1613684, 1969846, 1317591,\n",
       "       1317604, 1317614, 2592626,  913615, 1923960, 3210497, 2693435,\n",
       "       2111237,   24932, 2551017, 2551032, 2550995,  484609,  511430,\n",
       "       3016549, 3016557, 1624156, 2209990, 1948638, 2341452,  695423,\n",
       "       2022732, 2022736, 3277044,    1532, 3293959, 1610307, 1082582,\n",
       "       2710271, 2710281, 2710291,  618348, 1850392, 2111227,  414581,\n",
       "       2533395, 2111231,  667300, 3050540, 3050561, 2509091, 2509106,\n",
       "        736855,  326224,  326264,  326179,  842336, 3459455,  433031,\n",
       "       1337115,   48644,   48633, 1071513, 2996072, 2094142, 2094123,\n",
       "       2094158, 2111239, 3319364, 3319352, 3319326,  559638,      31,\n",
       "        881803,  881775, 1266077, 1266090, 3323586,  571326, 2804722,\n",
       "        793786,  881806,  881810,  881780, 2488628, 3399934, 3379740,\n",
       "       1422358,  782182, 2111224, 3047129, 3188729, 3188686,   68215,\n",
       "         68189,   68205, 1074834,   46272,  618350, 3511647,   90656,\n",
       "        422029,  422041, 1789273, 1789249, 1789261, 1789278, 2459312,\n",
       "       1140123, 3405637, 3441894, 1039165, 2878816, 1936175, 1341846,\n",
       "       1341857, 1341838, 1341855, 1341856,  134265, 2968815, 1105506,\n",
       "        617907,  110827, 2572860, 1310093, 1519570, 2761145, 3441901,\n",
       "       1140130, 3405644, 1039172, 3168483, 1207123, 1207113,  438299,\n",
       "        398084, 1916025, 1755235,  350165, 2536944, 2006770, 2006779,\n",
       "       2006787,  508416, 3206432, 3236130, 3236142,  148397,  148447,\n",
       "        148408,  148382,  148464,  148429, 1765078, 2448697,  769413,\n",
       "       2720302,  506766, 1052269, 2798932, 2798948, 1098668, 1898152,\n",
       "       1949970, 2716780, 3029859, 2932815, 2547397,  971124,  946356,\n",
       "       2903245, 1071526, 3109761, 1057700, 3357033,  253521, 2734850,\n",
       "       1848719, 1848705,  167842, 3321747, 1067705, 2559596,  768950,\n",
       "       2705932,  695115, 2071988,  350160, 2949601, 2949605,  460639,\n",
       "        460646, 2483915, 3202856, 3202842, 1533771, 1533779, 1533759,\n",
       "       1078190, 3173644, 1734051, 1438327, 1438319,  419797, 3010586,\n",
       "       3010596, 3010576, 3010609, 2919824, 2919810, 2919814, 2919820,\n",
       "       1547618, 3287412, 2318338,   91728,  192960, 1021689, 1020368,\n",
       "       1021650, 1021676, 1021657, 1021639,  326304, 3346690,   55537,\n",
       "         55552, 2900882, 1893611, 1893601,  821589,  932599,  932592,\n",
       "        932608,  971094, 1910564, 2515772,  896422, 2515764,  896471,\n",
       "        896456,  896437,  421401, 1850299, 1145899, 1145882, 1800806,\n",
       "        134875,  142047,  392151,  169153, 2667348, 2077024,   84750,\n",
       "       1093461, 1093424, 1546770, 1166547, 2703731, 2182879, 3408356,\n",
       "       3124496, 1912347,   10155,   10165, 2661540, 2862313, 2268822,\n",
       "       3171695, 1340651, 1340658,  380937, 2988152, 3346681, 3508139,\n",
       "       1671724, 1671731,  103771,  103785, 3219266,  326323, 3507572,\n",
       "       1005190,  170549, 2099716,  440215,  832015,  832007,  832030,\n",
       "       1786386, 3148981, 1966177, 1804831, 1687421, 2112748, 2005184,\n",
       "        186031,  881791, 1317283, 1317269,  172231,  172202, 3251393,\n",
       "       3251391, 3251381, 3251383, 1916024, 2664607, 2142282, 1141855,\n",
       "       3409854, 3370477, 2467241, 1039956,  720305, 1862096,  243048,\n",
       "       1862081, 1893563, 1004578, 1278514,  663159,  663148, 2321036,\n",
       "       2941630, 3251043, 3305893, 2795662, 2851590,  183733,  183755,\n",
       "       3333900, 1247854,  406779,  406765, 3080007,  560573, 1180369,\n",
       "         98049, 1104306, 1827984,  108044,  108062, 2253077, 1586065,\n",
       "       1586074,  415595, 2859085, 1687519,  664985,  664962, 2073748,\n",
       "       2073747, 1093433, 1093396, 1123689,  166523,  166535, 1315493,\n",
       "        120574, 2660454, 2660486, 2660471, 2466985,  475081, 3372998,\n",
       "       1138300, 1141770, 1141762, 2488715, 2488707, 2504006,  475089,\n",
       "       2127985, 1138308, 3373006, 3444750, 1422421, 3444742, 2466993,\n",
       "       2504014, 1422429,  445892,  445875,  445908,  445901,  445859,\n",
       "       1360542, 1360554, 1360579, 1360567,   99207, 1590235,  217698,\n",
       "       2721829,  308585, 3290888, 1697134, 2530080, 2530096,  946307,\n",
       "        244111, 2039040, 1318674, 1318656, 1121644,  472461,  569754,\n",
       "       2352568, 3251042,  563448, 2352569, 1052266,   75366, 2676451,\n",
       "       2172814,  441834,  441824,  441810,  508469,  508452,  508460,\n",
       "       1077476, 2568509, 3350769, 2499487, 2568520, 2030017, 1077484,\n",
       "       2030025, 3444906, 2499495,   31334, 1913024, 2183724, 2183716,\n",
       "       2030029, 3444914, 1913035,  224002,  224021,  239271,  239290,\n",
       "         16520, 1727437, 1727445, 1727453, 2253730, 2253711, 2253720,\n",
       "       2806163, 2806151,  296988, 3384554, 1290604,  807109, 1998076,\n",
       "        118430,   96759, 1064807,  525399,  871974, 2835096, 1978689,\n",
       "       1978707, 1978674, 1978720, 3002236, 1991060, 1875236, 1586393,\n",
       "       1586385, 1586373, 1875215, 2584904, 1431716, 2002114, 1090961,\n",
       "       1090989, 1090980,  585902,  877466,   83328,   83300,   31506,\n",
       "        413245,  123345, 1850906, 3512370, 3512382, 3512397, 1743237,\n",
       "        183537, 3059469, 1505074,  190538,  212338, 3335553, 1729947,\n",
       "       1729952, 2613810, 2869409, 1103834, 2869396, 2869384, 1103821,\n",
       "       1103809,  128455,  488980,  488964, 1578975, 1578964, 1578968,\n",
       "       2017857, 1332850, 1007873, 1007858, 1695392, 2013016, 2996422,\n",
       "        414121,  414104, 2017843, 3072389, 3472306,  940715, 1998063,\n",
       "        298485,  298484,  298434,  298462,  298459,  298460,  298474,\n",
       "        298473,  298476,  298458,  298488,  298486, 1436302, 1436307,\n",
       "       1436292,  336001, 2183131,  425202,  425194, 2949597,  762157,\n",
       "        762142, 1786101, 1786081, 1786095, 2389801, 2389788, 2389818,\n",
       "        125715, 2809935, 1837674,   18792,  969944,   80701, 2350082,\n",
       "       2878718,  213654,  213668,  526840,   44095, 2906869, 3379098,\n",
       "       3027774, 1906616,  543286,  543263,  543275, 3380584, 3380564,\n",
       "       1777634, 2374781, 1077725,  210440,  210422, 1561266,   95591,\n",
       "       2928851,  422138,  422122,  422114,  422086, 2225242, 2564305,\n",
       "       1911459, 1911474, 2830188, 1438315, 3374336,    5436, 2447282,\n",
       "       1671277, 2271276, 3034688, 1693726, 1550816, 1121312,   24288,\n",
       "         24270, 1900337, 3362012,   13908,  418140, 2800025, 3320202,\n",
       "       2070534, 3328133,  166312,  371121, 2844803, 3152799, 3214369,\n",
       "        185099, 2691967,  185081,   40048,   40064, 2485637, 3294023,\n",
       "          9963, 3016552, 1589022, 1589010, 1589008, 1588996, 1589020,\n",
       "       1588998, 2081416, 1716979, 1075487, 1075468,  488965,  488981,\n",
       "       2859317,  813783,  494688,  494678,  504071, 1158561, 2539570,\n",
       "        456434,  832174, 2809929,  864107,  864137,  143198,  143196,\n",
       "       2002113,  610452,  610453,  610451, 1354046, 3250185, 1552683,\n",
       "       1552669,     804, 1531002,     820, 3453841,  297012,  297042,\n",
       "        971794,  971774, 1646500, 2716781, 2250776,  864394, 2091832,\n",
       "       1714706, 3345880,  160819,  160834, 1914707,  291290, 3471583,\n",
       "       3471593, 1431109, 1743292, 1743326, 1743307, 3129705,  661281,\n",
       "        661300,  661284,   29489, 3125143,  134783, 3125157, 3125167,\n",
       "       1188465, 1188485, 1188478,  779381,   64547,  931875, 2651680,\n",
       "        529210, 1446495, 1660298,   51185, 3240494, 2202872, 1589329,\n",
       "        830124, 1814375, 2209988, 2209986,  163840,  393858, 2321067,\n",
       "       1453903, 2301473, 1127590, 2016263, 2016280,  567273,  567310,\n",
       "        102329, 1912002, 1586078, 1586055, 1237519, 2103532, 1658518,\n",
       "       1086606,   37199, 2210006,   37218, 1915077,  281649,  281703,\n",
       "        149472,  149519,  149488,  149496,  149511,  149464,  281676,\n",
       "       2074226, 1905944,  187340, 2512939,   32995,   33021,   33046,\n",
       "        185374,  460660, 3350759,  327862,  674491, 1310813, 1310811,\n",
       "       2901059,  126765, 2833627,  126751, 2462209, 2502632, 2462214,\n",
       "       1941809, 3091265, 3140289,  931694, 2502627, 3140294,  470495,\n",
       "        470490, 2750064,  126732,  931689, 3406889, 3406894, 1941814,\n",
       "       2487070, 2456646])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
